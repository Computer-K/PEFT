{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT 进阶操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 自定义模型适配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net1.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(target_modules=[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_peft_model(net1, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 多适配器加载与切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = LoraConfig(target_modules=[\"0\"])\n",
    "model2 = get_peft_model(net2, config1)\n",
    "model2.save_pretrained(\"./loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = LoraConfig(target_modules=[\"2\"])\n",
    "model2 = get_peft_model(net2, config2)\n",
    "model2.save_pretrained(\"./loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2)\n",
    ")\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = PeftModel.from_pretrained(net2, model_id=\"./loraA/\", adapter_name=\"loraA\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Sequential(\n",
       "      (0): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=10, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraA): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): lora.Linear(\n",
       "        (base_layer): Linear(in_features=10, out_features=2, bias=True)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (loraB): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (loraB): Linear(in_features=10, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (loraB): Linear(in_features=8, out_features=2, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_adapter(\"./loraB/\", adapter_name=\"loraB\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraA'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1325,  0.9759]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.0.base_layer.weight Parameter containing:\n",
      "tensor([[ 1.4645e-01,  7.1984e-02, -2.0617e-01, -2.6386e-01, -9.8245e-02,\n",
      "          2.5730e-01, -9.7435e-02, -1.7213e-01,  2.5057e-01, -1.3699e-01],\n",
      "        [-6.1466e-02, -2.6721e-01, -1.3274e-01,  4.7159e-02,  1.4495e-02,\n",
      "          2.6219e-01, -1.2239e-01, -2.4726e-01,  1.4580e-01,  1.7786e-01],\n",
      "        [-2.2877e-01, -9.2916e-02, -8.5293e-03, -1.2721e-01,  1.4724e-01,\n",
      "          1.8251e-01,  3.0822e-01,  1.3948e-01,  6.8516e-02,  2.5817e-01],\n",
      "        [-5.6962e-03,  1.4657e-01, -2.9567e-01,  2.8081e-01, -1.3695e-01,\n",
      "         -1.1256e-01,  1.5793e-01,  2.8332e-01,  1.5539e-01, -2.7911e-01],\n",
      "        [-2.5973e-01, -1.8877e-01,  2.3679e-01,  3.6140e-02, -1.9100e-01,\n",
      "          1.5634e-01, -4.2791e-02,  2.2269e-01,  2.6091e-01, -8.2455e-02],\n",
      "        [-1.4657e-01,  2.7296e-01,  9.0944e-02, -1.5734e-01,  4.5964e-02,\n",
      "          2.9930e-01, -2.1646e-01,  2.8357e-01,  2.9085e-01,  2.6478e-01],\n",
      "        [ 2.0233e-01,  3.1054e-05,  2.9408e-01, -2.8195e-02,  4.5281e-02,\n",
      "         -1.0098e-02, -2.9862e-01, -2.3266e-01,  2.1035e-01,  2.4095e-01],\n",
      "        [ 2.9444e-01, -2.6486e-01, -1.3805e-01,  6.5930e-02,  2.0918e-02,\n",
      "          1.4875e-01, -5.1024e-02, -3.1289e-01, -7.9984e-02, -2.7090e-01],\n",
      "        [ 2.3767e-02, -2.5000e-01,  2.6385e-01,  1.1457e-01, -7.2151e-02,\n",
      "          4.7032e-02, -5.4955e-02,  1.8905e-01, -3.0544e-02,  2.7292e-01],\n",
      "        [ 9.3039e-02,  9.7538e-02,  3.2974e-02,  7.3994e-02, -7.0705e-02,\n",
      "          2.2184e-01, -4.1765e-02, -2.3450e-01, -2.2023e-01, -1.4973e-01]])\n",
      "base_model.model.0.base_layer.bias Parameter containing:\n",
      "tensor([-0.0256,  0.2032, -0.2779,  0.2816, -0.0099,  0.1563,  0.2604, -0.1787,\n",
      "        -0.0314, -0.3001])\n",
      "base_model.model.0.lora_A.loraA.weight Parameter containing:\n",
      "tensor([[-0.0509,  0.1206,  0.1255, -0.2322,  0.0690,  0.1392, -0.3022,  0.2105,\n",
      "          0.1330,  0.2115],\n",
      "        [-0.2678,  0.1361, -0.0567, -0.2965,  0.1952,  0.0247, -0.0544, -0.1659,\n",
      "          0.1882,  0.2915],\n",
      "        [ 0.0242,  0.2682, -0.0705,  0.1581, -0.1435,  0.1073,  0.2150, -0.1434,\n",
      "          0.2721,  0.0943],\n",
      "        [ 0.2504,  0.2591,  0.1432,  0.0626,  0.2732, -0.0808, -0.0069,  0.3036,\n",
      "          0.1729,  0.2666],\n",
      "        [-0.0338, -0.2908,  0.0759, -0.0520,  0.3054,  0.0020, -0.0182,  0.1374,\n",
      "         -0.0760,  0.1852],\n",
      "        [ 0.2261, -0.1869,  0.1423,  0.0815, -0.2911,  0.0769,  0.2587, -0.1124,\n",
      "          0.0335, -0.2721],\n",
      "        [-0.2517, -0.0513,  0.3162,  0.0330,  0.2132, -0.1057,  0.2323,  0.2381,\n",
      "          0.1526,  0.1609],\n",
      "        [-0.3008,  0.2557, -0.1717, -0.0706, -0.2361, -0.0174, -0.2256,  0.2533,\n",
      "         -0.0513, -0.2989]], requires_grad=True)\n",
      "base_model.model.0.lora_B.loraA.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "base_model.model.2.base_layer.weight Parameter containing:\n",
      "tensor([[ 0.2633, -0.0497, -0.0212, -0.3113, -0.2187, -0.0380,  0.0645,  0.2442,\n",
      "          0.1512,  0.2274],\n",
      "        [ 0.0105,  0.1249,  0.1367, -0.2480,  0.2696, -0.0256,  0.0623,  0.2265,\n",
      "         -0.0618,  0.1057]])\n",
      "base_model.model.2.base_layer.bias Parameter containing:\n",
      "tensor([-0.2498, -0.2714])\n",
      "base_model.model.2.lora_A.loraB.weight Parameter containing:\n",
      "tensor([[-0.1783, -0.1366,  0.1005, -0.0456,  0.2602, -0.2584,  0.0375,  0.1739,\n",
      "          0.3020,  0.2362],\n",
      "        [-0.1662,  0.0961,  0.2236,  0.2731, -0.0218, -0.1000, -0.1231, -0.1007,\n",
      "         -0.1023,  0.2750],\n",
      "        [ 0.0951,  0.0121, -0.1860,  0.0094, -0.0690,  0.0604,  0.0874, -0.0849,\n",
      "          0.1026, -0.0289],\n",
      "        [-0.1445, -0.2892, -0.1486,  0.1642, -0.2377, -0.0043, -0.0280, -0.0295,\n",
      "         -0.0987, -0.2572],\n",
      "        [ 0.2134, -0.0032, -0.1024,  0.0800,  0.1069,  0.1318,  0.2579,  0.0244,\n",
      "         -0.2916,  0.0937],\n",
      "        [-0.0017,  0.1762,  0.0690,  0.0258, -0.0006,  0.1205,  0.1455, -0.2833,\n",
      "          0.2053,  0.0813],\n",
      "        [ 0.1105, -0.2233, -0.1585, -0.0097,  0.2364, -0.2673,  0.0161, -0.1874,\n",
      "          0.1202,  0.1384],\n",
      "        [-0.2065, -0.1648, -0.3121, -0.2594, -0.3039,  0.0522, -0.0834, -0.1579,\n",
      "          0.0765, -0.1230]])\n",
      "base_model.model.2.lora_B.loraB.weight Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if name in [\"base_model.model.0.lora_A.loraA.weight\", \"base_model.model.0.lora_B.loraA.weight\"]:\n",
    "        param.data = torch.ones_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[108.5005, 215.6204]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loraB'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.active_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1325,  0.9759]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 禁用适配器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_adapter(\"loraA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[108.5005, 215.6204]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(torch.arange(0, 10).view(1, 10).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1325,  0.9759]])\n"
     ]
    }
   ],
   "source": [
    "with model2.disable_adapter():\n",
    "    print(model2(torch.arange(0, 10).view(1, 10).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
